% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/estimatePopsize.fit.R
\name{estimatePopsize.fit}
\alias{estimatePopsize.fit}
\title{Regression fitting in single source capture-recapture models}
\usage{
estimatePopsize.fit(y, X, family, control, method, priorWeights, start, ...)
}
\arguments{
\item{y}{vector of dependent variables.}

\item{X}{model matrix, the vglm one.}

\item{family}{same as model in \code{estimatePopsize}.}

\item{control}{control parameters created in \code{controlModel}.}

\item{method}{method of estimation same as in \code{estimatePopsize}.}

\item{priorWeights}{vector of prior weights its the same argument as weights
in \code{estimatePopsize}.}

\item{start}{initial value of regression parameters.}

\item{...}{arguments to pass to other methods.}
}
\value{
List with regression parameters, working weights
(if IRLS fitting method) was chosen and number of iterations taken.
}
\description{
\code{estimatePopsize.fit} does for \code{estimatePopsize} what
\code{glm.fit} does for \code{glm}. It is internally called in
\code{estimatePopsize}. Since \code{estimatePopsize} does much more than
just regression fitting \code{estimatePopsize.fit} is much faster.
}
\details{
\loadmathjax

If \code{method} argument was set to \code{"optim"} the \code{stats::optim}
function will be used to fit regression with analyticly computed gradient and
(minus) log likelihood functions as \code{gr} and \code{fn} arguments.
Unfortunately \code{optim} does not allow for hessian to be specified.
More information about how to modify \code{optim} fitting is included in
\code{\link[=controlMethod]{controlMethod()}}.

If \code{method} argument was set to \code{"IRLS"} the iteratively reweighted
least squares. The algorithm is well know in generalised linear models.
Thomas W. Yee later extended this algorithm to vector generalised linear models
and in more general terms it can roughly be described as
(this is Yee's description after changing some conventions):
\enumerate{
\item Initialise with:
\itemize{
\item \code{converged <- FALSE}
\item \code{iter <- 1}
\item \mjteqn{\boldsymbol{\beta}}{\boldsymbol{\beta}}{}\code{ <- start}
\item \mjteqn{\boldsymbol{W}}{\boldsymbol{W}}{}\code{ <- prior}
\item \mjteqn{\ell}{\ell}{}\code{ <- }
\mjteqn{\ell(\boldsymbol{\beta})}{\ell(\boldsymbol{\beta})}{}
}
\item If \code{converged} or \code{iter > Maxiter} move to step 7.
\item Store values from previous algorithm step:
\itemize{
\item \mjteqn{\boldsymbol{W}_{-}}{\boldsymbol{W}_{-}}{}\code{ <- }
\mjteqn{\boldsymbol{W}}{\boldsymbol{W}}{}
\item \mjteqn{\ell_{-}}{\ell_{-}}{}\code{ <- }
\mjteqn{\ell}{\ell}{}
\item \mjteqn{\boldsymbol{\beta}_{-}}{\boldsymbol{\beta}_{-}}{}\code{ <- }
\mjteqn{\boldsymbol{\beta}}{\boldsymbol{\beta}}{}
} and assign values at current step:
\itemize{
\item \mjteqn{\boldsymbol{\eta}}{\boldsymbol{\eta}}{}\code{ <- }
\mjteqn{\boldsymbol{X}_{vlm}\boldsymbol{\beta}}{\boldsymbol{X}_{vlm}\boldsymbol{\beta}}{}
\item \mjteqn{Z_{i}}{Z_{i}}{}\code{ <- }
\mjteqn{\eta_{i}+\frac{\partial\ell_{i}}{\partial\eta_{i}}
E\left(\frac{\partial^{2}\ell_{i}}{
\partial\eta_{i}^{T}\partial\eta_{i}}\right)^{-1}}{
\eta_{i}+\frac{\partial\ell_{i}}{\partial\eta_{i}}
\mathbb{E}\left(\frac{\partial^{2}\ell_{i}}{
\partial\eta_{i}^{T}\partial\eta_{i}}\right)^{-1}}{}
\item \mjteqn{\boldsymbol{W}_{ij}}{\boldsymbol{W}_{ij}}{}\code{ <- }
\mjteqn{E\left(\frac{\partial^{2}\ell}{\partial\boldsymbol{\eta}_{j}^{T}
\partial\boldsymbol{\eta}_{i}}\right)}{
\mathbb{E}\left(\frac{\partial^{2}\ell}{
\partial\boldsymbol{\eta}_{j}^{T}\partial\boldsymbol{\eta}_{i}}\right)}{}
}
where \mjteqn{\ell_{i}}{\ell_{i}}{} is the ith component of log likelihood
function, \mjteqn{\eta_{i}}{\eta_{i}}{} is the vector of linear predictors
associated with ith row and \mjteqn{E\left(\frac{\partial^{2}\ell_{i}}{\partial\eta_{i}^{T}
\partial\eta_{i}}\right)}{\mathbb{E}\left(\frac{\partial^{2}\ell_{i}}{
\partial\eta_{i}^{T}\partial\eta_{i}}\right)}{}
corresponds to weights associated with ith row and \mjteqn{\boldsymbol{W}}{
\boldsymbol{W}}{} is a block matrix, made of diagonal matrixes
\mjteqn{E\left(\frac{\partial^{2}\ell}{\partial\boldsymbol{\eta}_{j}^{T}
\partial\boldsymbol{\eta}_{i}}\right)}{
\mathbb{E}\left(\frac{\partial^{2}\ell}{
\partial\boldsymbol{\eta}_{j}^{T}\partial\boldsymbol{\eta}_{i}}\right)}{}
\item Regress \mjteqn{\boldsymbol{Z}}{\boldsymbol{Z}}{} on
\mjteqn{\boldsymbol{X}_{vlm}}{\boldsymbol{X}_{vlm}}{} to obtain
\mjteqn{\boldsymbol{\beta}}{\boldsymbol{\beta}}{} as:
\mjtdeqn{\boldsymbol{\beta}=
\left(\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{X}_{vlm}\right)^{-1}
\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{Z}}{\boldsymbol{\beta}=
\left(\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{X}_{vlm}\right)^{-1}
\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{Z}}{}
\item Assign:
\itemize{
\item\code{converged <- }\mjteqn{
\ell(\boldsymbol{\beta})-\ell_{-}<}{
\ell(\boldsymbol{\beta})-\ell_{-}\lt}{}
\mjteqn{\varepsilon\cdot\ell_{-}}{\varepsilon\cdot\ell_{-}}{}
or
\mjteqn{||\boldsymbol{\beta}-\boldsymbol{\beta}_{-}||_{\infty}<\varepsilon}{
||\boldsymbol{\beta}-\boldsymbol{\beta}_{-}||_{\infty}\lt\varepsilon}{}
\item\code{iter <- iter + 1}
}
where \mjteqn{\varepsilon}{\varepsilon}{} is the relative tolerance level,
by default \code{1e-8}.
\item Return to step 2.
\item Return \mjteqn{\boldsymbol{\beta}, \boldsymbol{W}}{
\boldsymbol{\beta}, \boldsymbol{W}}{}, \code{iter}.
}

In this package we use different conventions for \mjteqn{\boldsymbol{X}_{vlm}}{
\boldsymbol{X}_{vlm}}{} matrix hence slight differences are present in
algorithm description but results are identical.
}
\examples{

# Get data
summary(farmsubmission)

# construct vglm model matrix
X <- matrix(data = 0, nrow = 2 * NROW(farmsubmission), ncol = 7)
X[1:NROW(farmsubmission), 1:4] <- model.matrix(
  ~ 1 + log_size + log_distance + C_TYPE, 
  farmsubmission
)

X[-(1:NROW(farmsubmission)), 5:7] <- X[1:NROW(farmsubmission), c(1, 3, 4)]

# this atrrtibute tells the function which elements of the design matrix 
# correspond to which linear predictor 
attr(X, "hwm") <- c(4, 3)

# get starting points
start <- glm.fit(
  y = farmsubmission$TOTAL_SUB, 
  x = X[1:NROW(farmsubmission), 1:4], 
  family = poisson()
)$coefficients

start <- c(start, 0, 0, 0)

# call function
res <- estimatePopsize.fit(
  y = farmsubmission$TOTAL_SUB, 
  X = X, 
  method = "IRLS", 
  priorWeights = 1, 
  family = ztoigeom(), 
  control = controlMethod(verbose = 5), 
  start = start
)

# extract results

# regression coefficient vector
res$beta

# check likelihood
ll <- ztnegbin()$makeMinusLogLike(y = farmsubmission$TOTAL_SUB, X = X)

-ll(res$beta)

# number of iterations
res$iter

# working weights
head(res$weights)

# Compare with optim call

res2 <- estimatePopsize.fit(
  y = farmsubmission$TOTAL_SUB, 
  X = X, 
  method = "optim", 
  priorWeights = 1, 
  family = ztoigeom(), 
  start = start, 
  control = controlMethod(verbose = 1)
)
# extract results

# regression coefficient vector
res2$beta


# check likelihood
-ll(res2$beta)

# number of calls to log lik function
# since optim does not return the number of
# iterations
res2$iter

# optim does not calculated working weights
head(res2$weights)

}
\references{
Yee, T. W. (2015). Vector Generalized Linear and Additive Models:
With an Implementation in R. New York, USA: Springer. ISBN 978-1-4939-2817-0.
}
\seealso{
\code{\link[stats:glm]{stats::glm()}} \code{\link[=estimatePopsize]{estimatePopsize()}} \code{\link[=controlMethod]{controlMethod()}} \code{\link[stats:optim]{stats::optim()}}
}
\author{
Piotr Chlebicki, Maciej Beresewicz
}
