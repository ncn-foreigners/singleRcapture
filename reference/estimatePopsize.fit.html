<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="estimatePopsize.fit does for estimatePopsize what
glm.fit does for glm. It is internally called in
estimatePopsize. Since estimatePopsize does much more than
just regression fitting estimatePopsize.fit is much faster."><title>Regression fitting in single source capture-recapture models — estimatePopsize.fit • singleRcapture</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Regression fitting in single source capture-recapture models — estimatePopsize.fit"><meta property="og:description" content="estimatePopsize.fit does for estimatePopsize what
glm.fit does for glm. It is internally called in
estimatePopsize. Since estimatePopsize does much more than
just regression fitting estimatePopsize.fit is much faster."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">singleRcapture</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/ncn-foreigners/singleRcapture/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Regression fitting in single source capture-recapture models</h1>
      <small class="dont-index">Source: <a href="https://github.com/ncn-foreigners/singleRcapture/blob/HEAD/R/estimatePopsize.fit.R" class="external-link"><code>R/estimatePopsize.fit.R</code></a></small>
      <div class="d-none name"><code>estimatePopsize.fit.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><code>estimatePopsize.fit</code> does for <code>estimatePopsize</code> what
<code>glm.fit</code> does for <code>glm</code>. It is internally called in
<code>estimatePopsize</code>. Since <code>estimatePopsize</code> does much more than
just regression fitting <code>estimatePopsize.fit</code> is much faster.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">estimatePopsize.fit</span><span class="op">(</span><span class="va">y</span>, <span class="va">X</span>, <span class="va">family</span>, <span class="va">control</span>, <span class="va">method</span>, <span class="va">priorWeights</span>, <span class="va">start</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>y</dt>
<dd><p>vector of dependent variables.</p></dd>


<dt>X</dt>
<dd><p>model matrix, the vglm one.</p></dd>


<dt>family</dt>
<dd><p>same as model in <code>estimatePopsize</code>.</p></dd>


<dt>control</dt>
<dd><p>control parameters created in <code>controlModel</code>.</p></dd>


<dt>method</dt>
<dd><p>method of estimation same as in <code>estimatePopsize</code>.</p></dd>


<dt>priorWeights</dt>
<dd><p>vector of prior weights its the same argument as weights
in <code>estimatePopsize</code>.</p></dd>


<dt>start</dt>
<dd><p>initial value of regression parameters.</p></dd>


<dt>...</dt>
<dd><p>arguments to pass to other methods.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>List with regression parameters, working weights
(if IRLS fitting method) was chosen and number of iterations taken.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p><script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>
<p>If <code>method</code> argument was set to <code>"optim"</code> the <code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim</a></code>
function will be used to fit regression with analytically computed gradient and
(minus) log likelihood functions as <code>gr</code> and <code>fn</code> arguments.
Unfortunately <code>optim</code> does not allow for hessian to be specified.
More information about how to modify <code>optim</code> fitting is included in
<code><a href="controlMethod.html">controlMethod()</a></code>.</p>
<p>If <code>method</code> argument was set to <code>"IRLS"</code> the iteratively reweighted
least squares. The algorithm is well know in generalised linear models.
Thomas W. Yee later extended this algorithm to vector generalised linear models
and in more general terms it can roughly be described as
(this is Yee's description after changing some conventions):</p><ol><li><p>Initialise with:</p><ul><li><p><code>converged &lt;- FALSE</code></p></li>
<li><p><code>iter &lt;- 1</code></p></li>
<li><p><em></em>\(\boldsymbol{\beta}\)<code> &lt;- start</code></p></li>
<li><p><em></em>\(\boldsymbol{W}\)<code> &lt;- prior</code></p></li>
<li><p><em></em>\(\ell\)<code> &lt;- </code><em></em>\(\ell(\boldsymbol{\beta})\)</p></li>
</ul></li>
<li><p>If <code>converged</code> or <code>iter &gt; Maxiter</code> move to step 7.</p></li>
<li><p>Store values from previous algorithm step:</p><ul><li><p><em></em>\(\boldsymbol{W}_{-}\)<code> &lt;- </code>
<em></em>\(\boldsymbol{W}\)</p></li>
<li><p><em></em>\(\ell_{-}\)<code> &lt;- </code>
<em></em>\(\ell\)</p></li>
<li><p><em></em>\(\boldsymbol{\beta}_{-}\)<code> &lt;- </code>
<em></em>\(\boldsymbol{\beta}\)</p></li>
</ul><p>and assign values at current step:</p><ul><li><p><em></em>\(\boldsymbol{\eta}\)<code> &lt;- </code>
<em></em>\(\boldsymbol{X}_{vlm}\boldsymbol{\beta}\)</p></li>
<li><p><em></em>\(Z_{i}\)<code> &lt;- </code>
<em></em>\(
\eta_{i}+\frac{\partial\ell_{i}}{\partial\eta_{i}}
\mathbb{E}\left(\frac{\partial^{2}\ell_{i}}{
\partial\eta_{i}^{T}\partial\eta_{i}}\right)^{-1}\)</p></li>
<li><p><em></em>\(\boldsymbol{W}_{ij}\)<code> &lt;- </code>
<em></em>\(\mathbb{E}\left(\frac{\partial^{2}\ell}{
\partial\boldsymbol{\eta}_{j}^{T}\partial\boldsymbol{\eta}_{i}}\right)\)</p></li>
</ul><p>where <em></em>\(\ell_{i}\) is the ith component of log likelihood
function, <em></em>\(\eta_{i}\) is the vector of linear predictors
associated with ith row and <em></em>\(\mathbb{E}\left(\frac{\partial^{2}\ell_{i}}{
\partial\eta_{i}^{T}\partial\eta_{i}}\right)\)
corresponds to weights associated with ith row and <em></em>\(\boldsymbol{W}\)
is a block matrix, made of diagonal matrixes
<em></em>\(\mathbb{E}\left(\frac{\partial^{2}\ell}{
\partial\boldsymbol{\eta}_{j}^{T}\partial\boldsymbol{\eta}_{i}}\right)\)</p></li>
<li><p>Regress <em></em>\(\boldsymbol{Z}\) on
<em></em>\(\boldsymbol{X}_{vlm}\) to obtain
<em></em>\(\boldsymbol{\beta}\) as:
\[\boldsymbol{\beta}=
\left(\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{X}_{vlm}\right)^{-1}
\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{Z}\]</p></li>
<li><p>Assign:</p><ul><li><p><code>converged &lt;- </code><em></em>\(
\ell(\boldsymbol{\beta})-\ell_{-} \(
||\boldsymbol{\beta}-\boldsymbol{\beta}_{-}||_{\infty} </p></li>
<li><p><code>iter &lt;- iter + 1</code></p></li>
</ul><p>where <em></em>\(\varepsilon\) is the relative tolerance level,
by default <code>1e-8</code>.</p></li>
<li><p>Return to step 2.</p></li>
<li><p>Return <em></em>\(\boldsymbol{\beta}, \boldsymbol{W}\), <code>iter</code>.</p></li>
</ol><p>In this package we use different conventions for <em></em>\(\boldsymbol{X}_{vlm}\)
matrix hence slight differences are present in algorithm description but
results are identical.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Yee, T. W. (2015). Vector Generalized Linear and Additive Models:
With an Implementation in R. New York, USA: Springer. ISBN 978-1-4939-2817-0.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">stats::glm()</a></code> <code><a href="estimatePopsize.html">estimatePopsize()</a></code> <code><a href="controlMethod.html">controlMethod()</a></code> <code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim()</a></code></p></div>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Piotr Chlebicki, Maciej Beresewicz</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co"># Get data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    TOTAL_SUB        log_size       log_distance      C_TYPE    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Min.   : 1.00   Min.   : 0.000   Min.   : 4.102   Beef :5336  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1st Qu.: 1.00   1st Qu.: 4.673   1st Qu.:10.351   Dairy:6700  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Median : 1.00   Median : 5.347   Median :10.778               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Mean   : 2.34   Mean   : 5.259   Mean   :10.662               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  3rd Qu.: 3.00   3rd Qu.: 5.940   3rd Qu.:11.099               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Max.   :47.00   Max.   :10.480   Max.   :12.097               </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># construct vglm model matrix</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fl">0</span>, nrow <span class="op">=</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">7</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">log_size</span> <span class="op">+</span> <span class="va">log_distance</span> <span class="op">+</span> <span class="va">C_TYPE</span>, </span></span>
<span class="r-in"><span>  <span class="va">farmsubmission</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span><span class="op">)</span>, <span class="fl">5</span><span class="op">:</span><span class="fl">7</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span><span class="op">]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># this atrrtibute tells the function which elements of the design matrix </span></span></span>
<span class="r-in"><span><span class="co"># correspond to which linear predictor </span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">X</span>, <span class="st">"hwm"</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># get starting points</span></span></span>
<span class="r-in"><span><span class="va">start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm.fit</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, </span></span>
<span class="r-in"><span>  x <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, </span></span>
<span class="r-in"><span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">start</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># call function</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">estimatePopsize.fit</span><span class="op">(</span></span></span>
<span class="r-in"><span>  y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, </span></span>
<span class="r-in"><span>  X <span class="op">=</span> <span class="va">X</span>, </span></span>
<span class="r-in"><span>  method <span class="op">=</span> <span class="st">"IRLS"</span>, </span></span>
<span class="r-in"><span>  priorWeights <span class="op">=</span> <span class="fl">1</span>, </span></span>
<span class="r-in"><span>  family <span class="op">=</span> <span class="fu"><a href="singleRmodels.html">ztoigeom</a></span><span class="op">(</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>  control <span class="op">=</span> <span class="fu"><a href="controlMethod.html">controlMethod</a></span><span class="op">(</span>verbose <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>  start <span class="op">=</span> <span class="va">start</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 1 log-likelihood: -17455.372</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.255494347  0.521900283 -0.048255922  0.321168020 -1.297382847  0.049409082 -0.726587214</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  1178.8778</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    639.53919  4035.62183  6732.72078   672.31223  -316.39394 -3358.16739  -229.50394</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 1.4296549</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 2 log-likelihood: -17289.531</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.859491920  0.627917105 -0.063516471  0.573159952 -2.327571214  0.074464787 -0.734988992</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  165.84115</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    77.37365182  329.72667483  823.92206208    0.28711463  -53.27713944 -568.21808076  -29.69092406</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 1.0301884</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 3 log-likelihood: -17279.272</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.710874025  0.613067896 -0.069548715  0.537208696 -2.550651004  0.071488122 -0.939145580</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  10.258788</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   35.9649654 218.1210745 385.4441808  32.8759028  -6.8429684 -71.8589804  -5.7178443</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.22307979</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 4 log-likelihood: -17278.776</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.78426085  0.61628333 -0.06440012  0.53843272 -3.10491635  0.12060422 -1.04138882</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.49548535</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   1.67966432 11.13935043 16.42827781  1.15147049 -0.53787945 -5.57182317 -0.74695785</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.55426534</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 5 log-likelihood: -17278.762</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.77818073  0.61674992 -0.06504016  0.53517478 -3.10447410  0.12145802 -1.08163762</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.014133264</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.232501334  2.204257359  2.694809270  0.131590616 -0.071608376 -0.605938875 -0.064356213</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.040248796</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 6 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.78602286  0.61698772 -0.06441877  0.53495927 -3.19325142  0.12969021 -1.08314735</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00072206104</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.0149254818 -0.0442854058 -0.2585639446 -0.0671445437 -0.0089103073 -0.1428452785 -0.0408361061</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.088777321</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 7 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.783307402  0.617006834 -0.064659772  0.534565433 -3.160032510  0.126742033 -1.087078105</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.000086867327</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.0219006963  0.2137543746  0.2878052106  0.0210725209 -0.0038258075 -0.0055588958  0.0088000042</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.033218913</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 8 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.785132183  0.617029483 -0.064506904  0.534668321 -3.181900933  0.128724679 -1.085840518</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00002149725</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.00917986044 -0.07823752476 -0.12764140893 -0.01528913768  0.00031447068 -0.01459257986 -0.00776040766</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.021868422</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 9 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.784182050  0.617023943 -0.064588093  0.534586386 -3.170374939  0.127687086 -1.086727858</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.0000064244196</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.00580810483  0.05244014329  0.07853720972  0.00778331030 -0.00057098473  0.00429221926  0.00373823938</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.011525994</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 10 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.784725925  0.617028507 -0.064541975  0.534626993 -3.176948180  0.128280435 -1.086273279</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.0000019945583</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.00307033642 -0.02728421573 -0.04201045343 -0.00448214639  0.00022935424 -0.00326931977 -0.00221219810</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.006573241</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 11 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.78442528  0.61702627 -0.06456754  0.53460327 -3.17330966  0.12795232 -1.08653540</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00000061988248</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.00175710834  0.01568170285  0.02390375474  0.00247668337 -0.00014882078  0.00161926853  0.00120723718</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0036385179</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 12 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.784593634  0.617027580 -0.064553239  0.534616288 -3.175346365  0.128136053 -1.086390890</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00000019314757</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.000968762304 -0.008641334328 -0.013216142726 -0.001385713857  0.000077984442 -0.000953809209 -0.000679710368</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0020367031</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 13 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.784499807  0.617026860 -0.064561213  0.534608978 -3.174211159  0.128033659 -1.086471902</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.000000060121238</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.000543879318  0.004849594593  0.007409081324  0.000772957725 -0.000044801246  0.000519451077  0.000377932793</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0011352061</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 14 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.784552191  0.617027265 -0.064556762  0.534613048 -3.174844941  0.128090828 -1.086426773</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.000000018728315</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.00030256412 -0.00269909096 -0.00412482654 -0.00043127032  0.00002466148 -0.00029328219 -0.00021122304</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.00063378215</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 15 log-likelihood: -17278.761</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.784522964  0.617027040 -0.064559245  0.534610775 -3.174491334  0.128058932 -1.086451974</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00000000583168</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.000169118291  0.001508137257  0.002304646966  0.000240720360 -0.000013855243  0.000162719782  0.000117791113</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0003536072</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of analytically computed hessian at fitted regression coefficients:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>             [,1]         [,2]         [,3]        [,4]       [,5]        [,6]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,]  -5533.0360  -31139.1628  -58786.3824  -3921.3952  407.46348  23473.8262</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,] -31139.1628 -179723.7217 -330742.8394 -22956.5461 4362.01544   1060.0139</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,] -58786.3824 -330742.8394 -627035.9660 -41504.3671  185.81715   4362.0154</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,]  -3921.3952  -22956.5461  -41504.3671  -3921.3952 2193.72685  46845.5137</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,]    407.4635     185.8172   46845.5137   1060.0139  -88.14760   -948.1115</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6,]   2193.7268    4362.0154    1971.9380   1971.9380 -948.11154 -10234.8910</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7,]   4362.0154   23473.8262     185.8172    185.8172  -28.97964   -312.6869</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            [,7]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,] 1971.93804</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,]  185.81715</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,] 1971.93804</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,]  185.81715</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,]  -28.97964</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6,] -312.68692</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7,]  -28.97964</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The matrix above has the following eigen values:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -811159.7+0i -17207.51+0i -2161.919+9274.748i -2161.919-9274.748i 6057.218+0i 1581.239+0i -1513.504+0i </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># extract results</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># regression coefficient vector</span></span></span>
<span class="r-in"><span><span class="va">res</span><span class="op">$</span><span class="va">beta</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -2.78452296  0.61702704 -0.06455925  0.53461077 -3.17449133  0.12805893</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7] -1.08645197</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># check likelihood</span></span></span>
<span class="r-in"><span><span class="va">ll</span> <span class="op">&lt;-</span> <span class="fu"><a href="singleRmodels.html">ztnegbin</a></span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">makeMinusLogLike</span><span class="op">(</span>y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, X <span class="op">=</span> <span class="va">X</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="op">-</span><span class="fu">ll</span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -19536.01</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># number of iterations</span></span></span>
<span class="r-in"><span><span class="va">res</span><span class="op">$</span><span class="va">iter</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 15</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># working weights</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>          lambda       mixed       mixed       omega</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,] 0.22688312 -0.03207963 -0.03207963 0.006351956</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,] 0.66642253 -0.03199578 -0.03199578 0.006238854</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,] 0.08469406 -0.01202233 -0.01202233 0.001899477</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,] 0.14084340 -0.01990317 -0.01990317 0.003397031</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,] 0.34099080 -0.04762290 -0.04762290 0.012045206</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6,] 0.42290801 -0.05782236 -0.05782236 0.018478738</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compare with optim call</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">res2</span> <span class="op">&lt;-</span> <span class="fu">estimatePopsize.fit</span><span class="op">(</span></span></span>
<span class="r-in"><span>  y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, </span></span>
<span class="r-in"><span>  X <span class="op">=</span> <span class="va">X</span>, </span></span>
<span class="r-in"><span>  method <span class="op">=</span> <span class="st">"optim"</span>, </span></span>
<span class="r-in"><span>  priorWeights <span class="op">=</span> <span class="fl">1</span>, </span></span>
<span class="r-in"><span>  family <span class="op">=</span> <span class="fu"><a href="singleRmodels.html">ztoigeom</a></span><span class="op">(</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>  start <span class="op">=</span> <span class="va">start</span>, </span></span>
<span class="r-in"><span>  control <span class="op">=</span> <span class="fu"><a href="controlMethod.html">controlMethod</a></span><span class="op">(</span>verbose <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   10 value 17321.626463</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   20 value 17301.696934</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   30 value 17281.887033</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   40 value 17281.801823</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   50 value 17281.438730</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   60 value 17280.194130</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   70 value 17280.188789</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   80 value 17280.176569</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter   90 value 17280.122521</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  100 value 17280.027214</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  110 value 17279.476714</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  120 value 17279.216352</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  130 value 17279.089746</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  140 value 17278.919206</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  150 value 17278.894635</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  160 value 17278.867207</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  170 value 17278.864148</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  180 value 17278.802633</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  190 value 17278.776768</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  200 value 17278.772490</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  210 value 17278.768282</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  220 value 17278.768123</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  230 value 17278.767875</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  240 value 17278.767809</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  250 value 17278.767469</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  260 value 17278.765452</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  270 value 17278.761627</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  280 value 17278.761313</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  290 value 17278.761310</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  300 value 17278.761306</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  310 value 17278.761304</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  320 value 17278.761298</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  330 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  340 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  350 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  360 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  370 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  380 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  390 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  400 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  410 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  420 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  430 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  440 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  450 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  460 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  470 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  480 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  490 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  500 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> iter  510 value 17278.761287</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> final  value 17278.761287 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> converged</span>
<span class="r-in"><span><span class="co"># extract results</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># regression coefficient vector</span></span></span>
<span class="r-in"><span><span class="va">res2</span><span class="op">$</span><span class="va">beta</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -2.78453076  0.61702707 -0.06455857  0.53461150 -3.17461277  0.12806986</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7] -1.08644213</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># check likelihood</span></span></span>
<span class="r-in"><span><span class="op">-</span><span class="fu">ll</span><span class="op">(</span><span class="va">res2</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -19536.01</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># number of calls to log lik function</span></span></span>
<span class="r-in"><span><span class="co"># since optim does not return the number of</span></span></span>
<span class="r-in"><span><span class="co"># iterations</span></span></span>
<span class="r-in"><span><span class="va">res2</span><span class="op">$</span><span class="va">iter</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> function gradient </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>      616      616 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># optim does not calculated working weights</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">res2</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1</span>
<span class="r-in"><span><span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Piotr Chlebicki, Maciej Beręsewicz.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

