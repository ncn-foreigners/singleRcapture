<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="estimatePopsize.fit does for estimatePopsize what
glm.fit does for glm. It is internally called in
estimatePopsize. Since estimatePopsize does much more than
just regression fitting estimatePopsize.fit is much faster."><title>Regression fitting in single source capture-recapture models — estimatePopsize.fit • singleRcapture</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Regression fitting in single source capture-recapture models — estimatePopsize.fit"><meta property="og:description" content="estimatePopsize.fit does for estimatePopsize what
glm.fit does for glm. It is internally called in
estimatePopsize. Since estimatePopsize does much more than
just regression fitting estimatePopsize.fit is much faster."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">singleRcapture</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.4</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/ncn-foreigners/singleRcapture/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Regression fitting in single source capture-recapture models</h1>
      <small class="dont-index">Source: <a href="https://github.com/ncn-foreigners/singleRcapture/blob/HEAD/R/estimatePopsize.fit.R" class="external-link"><code>R/estimatePopsize.fit.R</code></a></small>
      <div class="d-none name"><code>estimatePopsize.fit.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><code>estimatePopsize.fit</code> does for <code>estimatePopsize</code> what
<code>glm.fit</code> does for <code>glm</code>. It is internally called in
<code>estimatePopsize</code>. Since <code>estimatePopsize</code> does much more than
just regression fitting <code>estimatePopsize.fit</code> is much faster.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">estimatePopsize.fit</span><span class="op">(</span><span class="va">y</span>, <span class="va">X</span>, <span class="va">family</span>, <span class="va">control</span>, <span class="va">method</span>, <span class="va">priorWeights</span>, <span class="va">start</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>y</dt>
<dd><p>vector of dependent variables.</p></dd>


<dt>X</dt>
<dd><p>model matrix, the vglm one.</p></dd>


<dt>family</dt>
<dd><p>same as model in <code>estimatePopsize</code>.</p></dd>


<dt>control</dt>
<dd><p>control parameters created in <code>controlModel</code>.</p></dd>


<dt>method</dt>
<dd><p>method of estimation same as in <code>estimatePopsize</code>.</p></dd>


<dt>priorWeights</dt>
<dd><p>vector of prior weights its the same argument as weights
in <code>estimatePopsize</code>.</p></dd>


<dt>start</dt>
<dd><p>initial value of regression parameters.</p></dd>


<dt>...</dt>
<dd><p>arguments to pass to other methods.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>List with regression parameters, working weights
(if IRLS fitting method) was chosen and number of iterations taken.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>If <code>method</code> argument was set to <code>"optim"</code> the <code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim</a></code>
function will be used to fit regression with analyticly computed gradient and
(minus) log likelihood functions as <code>gr</code> and <code>fn</code> arguments.
Unfortunately <code>optim</code> does not allow for hessian to be specified.
More information about how to modify <code>optim</code> fitting is included in
<code><a href="controlMethod.html">controlMethod()</a></code>.</p>
<p>If <code>method</code> argument was set to <code>"IRLS"</code> the iteratively reweighted
least squares. The algorithm is well know in generalised linear models.
Thomas W. Yee later extended this algorithm to vector generalised linear models
and in more general terms it can roughly be described as
(this is Yee's description after changing some conventions):
<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p><ol><li><p>Initialise with:</p><ul><li><p><code>converged &lt;- FALSE</code></p></li>
<li><p><code>iter &lt;- 1</code></p></li>
<li><p><em></em>\(\boldsymbol{\beta}\)<code> &lt;- start</code></p></li>
<li><p><em></em>\(\boldsymbol{W}\)<code> &lt;- prior</code></p></li>
<li><p><em></em>\(\ell\)<code> &lt;- </code><em></em>\(\ell(\boldsymbol{\beta})\)</p></li>
</ul></li>
<li><p>If <code>converged</code> or <code>iter &gt; Maxiter</code> move to step 7.</p></li>
<li><p>Store values from previous algorithm step:</p><ul><li><p><em></em>\(\boldsymbol{W}_{-}\)<code> &lt;- </code><em></em>\(\boldsymbol{W}\)</p></li>
<li><p><em></em>\(\ell_{-}\)<code> &lt;- </code><em></em>\(\ell\)</p></li>
<li><p><em></em>\(\boldsymbol{\beta}_{-}\)<code> &lt;- </code><em></em>\(\boldsymbol{\beta}\)</p></li>
</ul><p>and assign values at current step:</p><ul><li><p><em></em>\(\boldsymbol{\eta}\)<code> &lt;- </code><em></em>\(\boldsymbol{X}_{vlm}\boldsymbol{\beta}\)</p></li>
<li><p><em></em>\(Z_{i}\)<code> &lt;- </code>
<em></em>\(\eta_{i}+\frac{\partial\ell_{i}}{\partial\eta_{i}}
\mathbb{E}\left(\frac{\partial^{2}\ell_{i}}{
\partial\eta_{i}^{T}\partial\eta_{i}}\right)^{-1}\)</p></li>
<li><p><em></em>\(\boldsymbol{W}_{ij}\)<code> &lt;- </code>
<em></em>\(\mathbb{E}\left(\frac{\partial^{2}\ell}{
\partial\boldsymbol{\eta}_{j}^{T}\partial\boldsymbol{\eta}_{i}}\right)\)</p></li>
</ul><p>where <em></em>\(\ell_{i}\) is the ith component of log likelihood function,
<em></em>\(\eta_{i}\) is the vector of linear predictors associated with
ith row and  <em></em>\(\mathbb{E}\left(\frac{\partial^{2}\ell_{i}}{\partial\eta_{i}^{T}\partial\eta_{i}}\right)\)
corresponds to weights associated with ith row and <em></em>\(\boldsymbol{W}\)
is a block matrix, made of diagonal matrixes
<em></em>\(\mathbb{E}\left(\frac{\partial^{2}\ell}{
\partial\boldsymbol{\eta}_{j}^{T}\partial\boldsymbol{\eta}_{i}}\right)\)</p></li>
<li><p>Regress <em></em>\(\boldsymbol{Z}\) on <em></em>\(\boldsymbol{X}_{vlm}\)
to obtain <em></em>\(\boldsymbol{\beta}\) as:
\[\boldsymbol{\beta}=
\left(\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{X}_{vlm}\right)^{-1}
\boldsymbol{X}_{vlm}^{T}\boldsymbol{W}\boldsymbol{Z}\]</p></li>
<li><p>Assign:</p><ul><li><p><code>converged &lt;- </code>
<em></em>\(\ell(\boldsymbol{\beta})-\ell_{-} \lt \varepsilon \ell_{-}\) <em></em>\(\lor\)
<em></em>\(||\boldsymbol{\beta}-\boldsymbol{\beta}_{-}||_{\infty} \lt \varepsilon\)</p></li>
<li><p><code>iter &lt;- iter + 1</code></p></li>
</ul><p>where <em></em>\(\varepsilon\) is the relative tolerance level, by default <code>1e-8</code>.</p></li>
<li><p>Return to step 2.</p></li>
<li><p>Return <em></em>\(\boldsymbol{\beta}, \boldsymbol{W}\), <code>iter</code>.</p></li>
</ol><p>In this package we use different conventions for <em></em>\(\boldsymbol{X}_{vlm}\)
matrix hence slight differences are present in algorithm description but
results are identical.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Yee, T. W. (2015). Vector Generalized Linear and Additive Models:
With an Implementation in R. New York, USA: Springer. ISBN 978-1-4939-2817-0.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">stats::glm()</a></code> <code><a href="estimatePopsize.html">estimatePopsize()</a></code> <code><a href="controlMethod.html">controlMethod()</a></code> <code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim()</a></code></p></div>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Piotr Chlebicki, Maciej Beręsewicz</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># Get data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    TOTAL_SUB        log_size       log_distance      C_TYPE    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Min.   : 1.00   Min.   : 0.000   Min.   : 4.102   Beef :5336  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1st Qu.: 1.00   1st Qu.: 4.673   1st Qu.:10.351   Dairy:6700  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Median : 1.00   Median : 5.347   Median :10.778               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Mean   : 2.34   Mean   : 5.259   Mean   :10.662               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  3rd Qu.: 3.00   3rd Qu.: 5.940   3rd Qu.:11.099               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Max.   :47.00   Max.   :10.480   Max.   :12.097               </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># construct vglm model matrix</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fl">0</span>, nrow <span class="op">=</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">7</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">log_size</span> <span class="op">+</span> <span class="va">log_distance</span> <span class="op">+</span> <span class="va">C_TYPE</span>, </span></span>
<span class="r-in"><span>                                               <span class="va">farmsubmission</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span><span class="op">)</span>, <span class="fl">5</span><span class="op">:</span><span class="fl">7</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span><span class="op">]</span></span></span>
<span class="r-in"><span><span class="co"># this atrrtibute tells the function which elements of the design matrix </span></span></span>
<span class="r-in"><span><span class="co"># correspond to which linear predictor </span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">X</span>, <span class="st">"hwm"</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># get starting points</span></span></span>
<span class="r-in"><span><span class="va">start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm.fit</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, </span></span>
<span class="r-in"><span>                 x <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">farmsubmission</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, </span></span>
<span class="r-in"><span>                 family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span></span></span>
<span class="r-in"><span><span class="va">start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">start</span>, <span class="va">start</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">6</span><span class="op">]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># call function</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">estimatePopsize.fit</span><span class="op">(</span></span></span>
<span class="r-in"><span>  y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, X <span class="op">=</span> <span class="va">X</span>, </span></span>
<span class="r-in"><span>  method <span class="op">=</span> <span class="st">"IRLS"</span>, </span></span>
<span class="r-in"><span>  priorWeights <span class="op">=</span> <span class="fl">1</span>, </span></span>
<span class="r-in"><span>  family <span class="op">=</span> <span class="fu"><a href="singleRmodels.html">ztnegbin</a></span><span class="op">(</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>  control <span class="op">=</span> <span class="fu"><a href="controlMethod.html">controlMethod</a></span><span class="op">(</span>verbose <span class="op">=</span> <span class="fl">5</span>, stepsize <span class="op">=</span> <span class="fl">.75</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>  start <span class="op">=</span> <span class="va">start</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 1 log-likelihood: -17823.492</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -1.863614075  0.475204651 -0.059013713  0.508672480 -0.327870976  0.086003423 -0.412206923</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  901.05075</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -1990.34014 -10046.54007 -21321.73120   -881.45386   -716.47130  -7710.75888   -223.33219</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 1.0377746</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 2 log-likelihood: -17437.868</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -2.83898496  0.57720331 -0.10523289  1.12721800  0.56681332  0.10483162 -1.23066712</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  385.62401</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    -952.47828  -4741.57396 -10212.18518   -343.98244   -618.99520  -6663.80140   -154.63239</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.97537088</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 3 log-likelihood: -17295.872</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.277460156  0.634940802 -0.094367509  2.034789937  2.128998318  0.045964537 -2.151291285</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  141.99625</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -413.851502 -2040.578657 -4436.735470  -109.135451  -335.376402 -3612.781025   -58.889278</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 1.562185</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 4 log-likelihood: -17254.782</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -5.072408286  0.657156480 -0.065245482  2.381886041  2.961574999 -0.012066361 -2.398344381</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  41.090197</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -139.197813  -687.872162 -1494.327940   -31.450516  -119.173553 -1288.504052   -18.285250</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.83257668</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 5 log-likelihood: -17249.508</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.785542658  0.662080248 -0.044539312  1.847021276  2.738430184 -0.051852315 -1.769105789</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  5.2739327</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -62.5681200 -316.4732532 -673.2851829   -8.2755289  -52.4549093 -567.4986454   -4.9417204</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.62923859</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 6 log-likelihood: -17248.248</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.838358102  0.662181992 -0.035679178  1.805785896  2.842862541 -0.069778744 -1.688871750</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  1.2603975</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -18.0169421  -92.8169585 -193.8385273   -1.8798049  -15.1781828 -164.9037392   -1.1047930</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.10443236</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 7 log-likelihood: -17248.124</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.856424279  0.661637750 -0.030877664  1.776299716  2.894932574 -0.079055152 -1.644112756</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.12375469</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -5.06601911 -26.72531290 -54.37487852  -0.31528393  -4.27867262 -46.73618805  -0.15560324</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.052070032</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 8 log-likelihood: -17248.111</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.869878276  0.661294400 -0.028509607  1.766665256  2.926220022 -0.083411593 -1.629501617</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.012599044</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -1.3791306185  -7.4663980661 -14.7133524835  -0.0027426914  -1.1676544673 -12.8743485954   0.0215439672</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.031287448</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 9 log-likelihood: -17248.11</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.878959253  0.661144077 -0.027331378  1.764109284  2.944258141 -0.085493615 -1.625463512</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.0014672115</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.368913065 -2.048699268 -3.884684644  0.031430474 -0.312178145 -3.504357533  0.030488340</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.018038119</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 10 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.884625375  0.661089164 -0.026731658  1.763718234  2.954460230 -0.086525598 -1.624686621</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00022648247</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.096875744 -0.548122695 -0.991559296  0.020795430 -0.081408996 -0.947603064  0.017228273</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.010202089</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 11 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.888000502  0.661072319 -0.026419129  1.763867036  2.960181751 -0.087055092 -1.624768843</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.000047774331</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.0244397651 -0.1376704317 -0.2338731302  0.0104103315 -0.0201292559 -0.2533524486  0.0078301405</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0057215212</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 12 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.889956420  0.661068670 -0.026253010  1.764077434  2.963376789 -0.087334144 -1.624992315</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.000012449145</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.0055313064 -0.0285989665 -0.0431543682  0.0047561975 -0.0043078410 -0.0657477152  0.0032151064</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0031950377</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 13 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.891071396  0.661068881 -0.026163395  1.764238408  2.965156867 -0.087484001 -1.625177606</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.0000035915436</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -0.00084286134 -0.00187662677  0.00006712155  0.00211608014 -0.00049470766 -0.01574614830  0.00124263181</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0017800781</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 14 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.891700725  0.661069844 -0.026114548  1.764342988  2.966147382 -0.087565490 -1.625301537</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.0000010801996</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.00015910985  0.00314638510  0.00679966516  0.00094773468  0.00025496115 -0.00292540930  0.00045995750</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.00099051501</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 15 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.892053814  0.661070692 -0.026087737  1.764406292  2.966698186 -0.087610160 -1.625377602</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00000033018296</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.000267949697 0.003028308015 0.005713247289 0.000435422817 0.000291345164 0.000027911184 0.000163958646</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.00055080374</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 16 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.892251193  0.661071277 -0.026072955  1.764443253  2.967004372 -0.087634771 -1.625422349</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.00000010155782</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.000201240710 0.002082281200 0.003738961046 0.000207088974 0.000204770704 0.000491982940 0.000056070532</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.0003061859</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 17 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.892361281  0.661071643 -0.026064781  1.764464407  2.967174548 -0.087648375 -1.625448069</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.000000031312084</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.000127397155 0.001284304865 0.002245575651 0.000102112246 0.000126264478 0.000412962287 0.000018089806</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.00017017649</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration number 18 log-likelihood: -17248.109</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameter vector:  -4.892422599  0.661071861 -0.026060253  1.764476375  2.967269123 -0.087655909 -1.625462658</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log-likelihood reduction:  0.0000000096661097</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of gradient at current step:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.0000755209312 0.0007549148594 0.0012988453582 0.0000520085308 0.0000738565809 0.0002710898226 0.0000052602827</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Algorithm will terminate if one of following conditions will be met:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The increase to minus log-likelihood will be bellow chosen value of epsilon 1e-08 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Maximum change to the vector of regression parameters will be bellow the chosen value of epsilon.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> At current step the highest change was: 0.000094575234</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ----</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Value of analytically computed hessian at fitted regression coefficients:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            [,1]        [,2]        [,3]       [,4]        [,5]        [,6]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,]  -4571.199  -25603.055  -48636.535  -3380.822  -2509.0413 -145504.055</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,] -25603.055 -147121.914 -272342.907 -19693.777 -26719.7905   -8691.146</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,] -48636.535 -272342.907 -519445.459 -35856.227  -1501.4754  -26719.790</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,]  -3380.822  -19693.777  -35856.227  -3380.822 -13666.9336 -285668.710</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,]  -2509.041   -1501.475 -285668.710  -8691.146  -1717.8462  -18309.468</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6,] -13666.934  -26719.790  -15908.320 -15908.320 -18309.4675 -195877.421</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7,] -26719.790 -145504.055   -1501.475  -1501.475   -860.5633   -9111.942</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>             [,7]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,] -15908.3204</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,]  -1501.4754</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,] -15908.3204</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,]  -1501.4754</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,]   -860.5633</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6,]  -9111.9423</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7,]   -860.5633</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The matrix above has the following eigen values:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  -681851.2+0i -215719.6+0i -2322.41+58791.38i -2322.41-58791.38i 25652.64+0i 10560.49+0i -6972.756+0i </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># extract results</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># regression coefficient vector</span></span></span>
<span class="r-in"><span><span class="va">res</span><span class="op">$</span><span class="va">beta</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -4.89242260  0.66107186 -0.02606025  1.76447637  2.96726912 -0.08765591</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7] -1.62546266</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># check likelihood</span></span></span>
<span class="r-in"><span><span class="va">ll</span> <span class="op">&lt;-</span> <span class="fu"><a href="singleRmodels.html">ztnegbin</a></span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">makeMinusLogLike</span><span class="op">(</span>y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, X <span class="op">=</span> <span class="va">X</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="op">-</span><span class="fu">ll</span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -17248.11</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># number of iterations</span></span></span>
<span class="r-in"><span><span class="va">res</span><span class="op">$</span><span class="va">iter</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 18</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># working weights</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>          lambda      mixed      mixed      alpha</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,] 0.19146547 0.16520177 0.16520177 0.14282624</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,] 0.57006082 0.23023980 0.23023980 0.13334928</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,] 0.07855612 0.06890872 0.06890872 0.06047553</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,] 0.12737155 0.11112052 0.11112052 0.09703535</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,] 0.25529253 0.21624875 0.21624875 0.18398582</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6,] 0.28665185 0.23845695 0.23845695 0.19987565</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compare with optim call</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">res2</span> <span class="op">&lt;-</span> <span class="fu">estimatePopsize.fit</span><span class="op">(</span></span></span>
<span class="r-in"><span>  y <span class="op">=</span> <span class="va">farmsubmission</span><span class="op">$</span><span class="va">TOTAL_SUB</span>, X <span class="op">=</span> <span class="va">X</span>, </span></span>
<span class="r-in"><span>  method <span class="op">=</span> <span class="st">"optim"</span>, </span></span>
<span class="r-in"><span>  priorWeights <span class="op">=</span> <span class="fl">1</span>, </span></span>
<span class="r-in"><span>  family <span class="op">=</span> <span class="fu"><a href="singleRmodels.html">ztnegbin</a></span><span class="op">(</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>  start <span class="op">=</span> <span class="va">start</span>, </span></span>
<span class="r-in"><span>  control <span class="op">=</span> <span class="fu"><a href="controlMethod.html">controlMethod</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># extract results</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># regression coefficient vector</span></span></span>
<span class="r-in"><span><span class="va">res2</span><span class="op">$</span><span class="va">beta</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -4.89254268  0.66107233 -0.02604925  1.76447646  2.96745272 -0.08767306</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7] -1.62546335</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># check likelihood</span></span></span>
<span class="r-in"><span><span class="op">-</span><span class="fu">ll</span><span class="op">(</span><span class="va">res2</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -17248.11</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># number of calls to log lik function</span></span></span>
<span class="r-in"><span><span class="co"># since optim does not return the number of</span></span></span>
<span class="r-in"><span><span class="co"># iterations</span></span></span>
<span class="r-in"><span><span class="va">res2</span><span class="op">$</span><span class="va">iter</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> function gradient </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     1003     1003 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># optim does not calculated working weights</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">res2</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1</span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Piotr Chlebicki, Maciej Beręsewicz.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

